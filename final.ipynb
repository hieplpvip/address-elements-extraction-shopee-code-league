{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -q pandas sklearn ohmeow-blurr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None\n",
    "df = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300000, 45000)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ast\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_df, test_df = train_test_split(df, test_size=0.15, random_state=75)\n",
    "\n",
    "train_df = pd.read_csv('train.csv')\n",
    "\n",
    "# df_converters = {'tokens': ast.literal_eval, 'labels': ast.literal_eval}\n",
    "# train_df = pd.read_csv('train-ner-2.csv', converters=df_converters)\n",
    "\n",
    "len(train_df), len(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from string import punctuation\n",
    "import re\n",
    "\n",
    "def clean(s):\n",
    "    res = re.sub(r'(\\w)(\\()(\\w)', '\\g<1> \\g<2>\\g<3>', s)\n",
    "    res = re.sub(r'(\\w)([),.:;]+)(\\w)', '\\g<1>\\g<2> \\g<3>', res)\n",
    "    res = re.sub(r'(\\w)(\\.\\()(\\w)', '\\g<1>. (\\g<3>', res)\n",
    "    res = re.sub(r'\\s+', ' ', res)\n",
    "    res = res.strip()\n",
    "    return res\n",
    "\n",
    "def stripclean(arr):\n",
    "    return [s.strip().strip(punctuation) for s in arr]\n",
    "\n",
    "def dummy(x):\n",
    "    # stupid workaround to deep copy array cause i couldn't get it to work properly\n",
    "    return [s for s in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['POI'] = train_df['POI/street'].str.split('/').str[0].apply(clean).str.split().apply(stripclean)\n",
    "train_df['STR'] = train_df['POI/street'].str.split('/').str[1].apply(clean).str.split().apply(stripclean)\n",
    "train_df['tokens'] = train_df['raw_address'].apply(clean).str.split()\n",
    "train_df['strip_tokens'] = train_df['tokens'].apply(stripclean)\n",
    "train_df['full_tokens'] = train_df['tokens'].apply(dummy)\n",
    "train_df['labels'] = train_df['tokens'].apply(lambda x : ['O'] * len(x))\n",
    "train_df['pos_poi'] = train_df['tokens'].apply(lambda x : [-1, -1])\n",
    "train_df['pos_str'] = train_df['tokens'].apply(lambda x : [-1, -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>raw_address</th>\n",
       "      <th>POI/street</th>\n",
       "      <th>POI</th>\n",
       "      <th>STR</th>\n",
       "      <th>tokens</th>\n",
       "      <th>strip_tokens</th>\n",
       "      <th>full_tokens</th>\n",
       "      <th>labels</th>\n",
       "      <th>pos_poi</th>\n",
       "      <th>pos_str</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>jl kapuk timur delta sili iii lippo cika 11 a ...</td>\n",
       "      <td>/jl kapuk timur delta sili iii lippo cika</td>\n",
       "      <td>[]</td>\n",
       "      <td>[jl, kapuk, timur, delta, sili, iii, lippo, cika]</td>\n",
       "      <td>[jl, kapuk, timur, delta, sili, iii, lippo, ci...</td>\n",
       "      <td>[jl, kapuk, timur, delta, sili, iii, lippo, ci...</td>\n",
       "      <td>[jl, kapuk, timur, delta, sili, iii, lippo, ci...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n",
       "      <td>[-1, -1]</td>\n",
       "      <td>[-1, -1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>aye, jati sampurna</td>\n",
       "      <td>/</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[aye,, jati, sampurna]</td>\n",
       "      <td>[aye, jati, sampurna]</td>\n",
       "      <td>[aye,, jati, sampurna]</td>\n",
       "      <td>[O, O, O]</td>\n",
       "      <td>[-1, -1]</td>\n",
       "      <td>[-1, -1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>setu siung 119 rt 5 1 13880 cipayung</td>\n",
       "      <td>/siung</td>\n",
       "      <td>[]</td>\n",
       "      <td>[siung]</td>\n",
       "      <td>[setu, siung, 119, rt, 5, 1, 13880, cipayung]</td>\n",
       "      <td>[setu, siung, 119, rt, 5, 1, 13880, cipayung]</td>\n",
       "      <td>[setu, siung, 119, rt, 5, 1, 13880, cipayung]</td>\n",
       "      <td>[O, O, O, O, O, O, O, O]</td>\n",
       "      <td>[-1, -1]</td>\n",
       "      <td>[-1, -1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>toko dita, kertosono</td>\n",
       "      <td>toko dita/</td>\n",
       "      <td>[toko, dita]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[toko, dita,, kertosono]</td>\n",
       "      <td>[toko, dita, kertosono]</td>\n",
       "      <td>[toko, dita,, kertosono]</td>\n",
       "      <td>[O, O, O]</td>\n",
       "      <td>[-1, -1]</td>\n",
       "      <td>[-1, -1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>jl. orde baru</td>\n",
       "      <td>/jl. orde baru</td>\n",
       "      <td>[]</td>\n",
       "      <td>[jl, orde, baru]</td>\n",
       "      <td>[jl., orde, baru]</td>\n",
       "      <td>[jl, orde, baru]</td>\n",
       "      <td>[jl., orde, baru]</td>\n",
       "      <td>[O, O, O]</td>\n",
       "      <td>[-1, -1]</td>\n",
       "      <td>[-1, -1]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                        raw_address  \\\n",
       "0   0  jl kapuk timur delta sili iii lippo cika 11 a ...   \n",
       "1   1                                 aye, jati sampurna   \n",
       "2   2               setu siung 119 rt 5 1 13880 cipayung   \n",
       "3   3                               toko dita, kertosono   \n",
       "4   4                                      jl. orde baru   \n",
       "\n",
       "                                  POI/street           POI  \\\n",
       "0  /jl kapuk timur delta sili iii lippo cika            []   \n",
       "1                                          /            []   \n",
       "2                                     /siung            []   \n",
       "3                                 toko dita/  [toko, dita]   \n",
       "4                             /jl. orde baru            []   \n",
       "\n",
       "                                                 STR  \\\n",
       "0  [jl, kapuk, timur, delta, sili, iii, lippo, cika]   \n",
       "1                                                 []   \n",
       "2                                            [siung]   \n",
       "3                                                 []   \n",
       "4                                   [jl, orde, baru]   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  [jl, kapuk, timur, delta, sili, iii, lippo, ci...   \n",
       "1                             [aye,, jati, sampurna]   \n",
       "2      [setu, siung, 119, rt, 5, 1, 13880, cipayung]   \n",
       "3                           [toko, dita,, kertosono]   \n",
       "4                                  [jl., orde, baru]   \n",
       "\n",
       "                                        strip_tokens  \\\n",
       "0  [jl, kapuk, timur, delta, sili, iii, lippo, ci...   \n",
       "1                              [aye, jati, sampurna]   \n",
       "2      [setu, siung, 119, rt, 5, 1, 13880, cipayung]   \n",
       "3                            [toko, dita, kertosono]   \n",
       "4                                   [jl, orde, baru]   \n",
       "\n",
       "                                         full_tokens  \\\n",
       "0  [jl, kapuk, timur, delta, sili, iii, lippo, ci...   \n",
       "1                             [aye,, jati, sampurna]   \n",
       "2      [setu, siung, 119, rt, 5, 1, 13880, cipayung]   \n",
       "3                           [toko, dita,, kertosono]   \n",
       "4                                  [jl., orde, baru]   \n",
       "\n",
       "                                    labels   pos_poi   pos_str  \n",
       "0  [O, O, O, O, O, O, O, O, O, O, O, O, O]  [-1, -1]  [-1, -1]  \n",
       "1                                [O, O, O]  [-1, -1]  [-1, -1]  \n",
       "2                 [O, O, O, O, O, O, O, O]  [-1, -1]  [-1, -1]  \n",
       "3                                [O, O, O]  [-1, -1]  [-1, -1]  \n",
       "4                                [O, O, O]  [-1, -1]  [-1, -1]  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['tokens'] = test_df['raw_address'].apply(clean).str.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>raw_address</th>\n",
       "      <th>POI/street</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>90142</th>\n",
       "      <td>90142</td>\n",
       "      <td>lom 88 asrikaton</td>\n",
       "      <td>/</td>\n",
       "      <td>[lom, 88, asrikaton]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163531</th>\n",
       "      <td>163531</td>\n",
       "      <td>varia usaha ungaran, peri kem pudakpayung</td>\n",
       "      <td>/</td>\n",
       "      <td>[varia, usaha, ungaran,, peri, kem, pudakpayung]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233950</th>\n",
       "      <td>233950</td>\n",
       "      <td>hutan gar no 7 20371 percut sei tuan</td>\n",
       "      <td>/gar</td>\n",
       "      <td>[hutan, gar, no, 7, 20371, percut, sei, tuan]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126157</th>\n",
       "      <td>126157</td>\n",
       "      <td>wardah gor srik ton,</td>\n",
       "      <td>wardah gorden/srik ton</td>\n",
       "      <td>[wardah, gor, srik, ton,]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96808</th>\n",
       "      <td>96808</td>\n",
       "      <td>green puri 7 cengkareng</td>\n",
       "      <td>/green puri 7</td>\n",
       "      <td>[green, puri, 7, cengkareng]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id                                raw_address  \\\n",
       "90142    90142                           lom 88 asrikaton   \n",
       "163531  163531  varia usaha ungaran, peri kem pudakpayung   \n",
       "233950  233950       hutan gar no 7 20371 percut sei tuan   \n",
       "126157  126157                       wardah gor srik ton,   \n",
       "96808    96808                    green puri 7 cengkareng   \n",
       "\n",
       "                    POI/street  \\\n",
       "90142                        /   \n",
       "163531                       /   \n",
       "233950                    /gar   \n",
       "126157  wardah gorden/srik ton   \n",
       "96808            /green puri 7   \n",
       "\n",
       "                                                  tokens  \n",
       "90142                               [lom, 88, asrikaton]  \n",
       "163531  [varia, usaha, ungaran,, peri, kem, pudakpayung]  \n",
       "233950     [hutan, gar, no, 7, 20371, percut, sei, tuan]  \n",
       "126157                         [wardah, gor, srik, ton,]  \n",
       "96808                       [green, puri, 7, cengkareng]  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build word list and token labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordlist_raw = {}\n",
    "POI_ERR_IDX = []\n",
    "STR_ERR_IDX = []\n",
    "SHORTEN_IDX = []\n",
    "OVERLAP_IDX = set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300000/300000 [02:26<00:00, 2044.00it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "for idx in tqdm(range(len(train_df))):\n",
    "    row = train_df.iloc[idx]\n",
    "    found_poi, found_str, shorten = False, False, False\n",
    "    for i in range(len(row['strip_tokens'])):\n",
    "        if row['strip_tokens'][i] == '': continue\n",
    "        if len(row['POI']) > 0 and row['POI'][0].startswith(row['strip_tokens'][i]):\n",
    "            ok = True\n",
    "            for j in range(len(row['POI'])):\n",
    "                if i + j >= len(row['strip_tokens']) or not row['POI'][j].startswith(row['strip_tokens'][i + j]):\n",
    "                    ok = False\n",
    "                    break\n",
    "            if ok:\n",
    "                found_poi = True\n",
    "                row['pos_poi'][0] = i\n",
    "                row['pos_poi'][1] = i + len(row['POI']) - 1\n",
    "                for j in range(len(row['POI'])):\n",
    "                    #assert row['labels'][i + j] == 'O'\n",
    "                    if row['labels'][i + j] != 'O':\n",
    "                        OVERLAP_IDX.add(row['id'])\n",
    "                    if len(row['POI']) == 1:       row['labels'][i + j] = 'S-POI'\n",
    "                    elif j == 0:                   row['labels'][i + j] = 'B-POI'\n",
    "                    elif j == len(row['POI']) - 1: row['labels'][i + j] = 'E-POI'\n",
    "                    else:                          row['labels'][i + j] = 'I-POI'\n",
    "                    if row['strip_tokens'][i + j] != row['POI'][j]:\n",
    "                        row['full_tokens'][i + j] = row['full_tokens'][i + j].replace(row['strip_tokens'][i + j], row['POI'][j])\n",
    "                        row['labels'][i + j] += '-SHORT'\n",
    "                        shorten = True\n",
    "                        if not row['strip_tokens'][i + j] in wordlist_raw: wordlist_raw[row['strip_tokens'][i + j]] = {}\n",
    "                        if not row['POI'][j] in wordlist_raw[row['strip_tokens'][i + j]]: wordlist_raw[row['strip_tokens'][i + j]][row['POI'][j]] = 0\n",
    "                        wordlist_raw[row['strip_tokens'][i + j]][row['POI'][j]] += 1\n",
    "        \n",
    "        if len(row['STR']) > 0 and row['STR'][0].startswith(row['strip_tokens'][i]):\n",
    "            ok = True\n",
    "            for j in range(len(row['STR'])):\n",
    "                if i + j >= len(row['strip_tokens']) or not row['STR'][j].startswith(row['strip_tokens'][i + j]):\n",
    "                    ok = False\n",
    "                    break\n",
    "            if ok:\n",
    "                found_str = True\n",
    "                row['pos_str'][0] = i\n",
    "                row['pos_str'][1] = i + len(row['STR']) - 1\n",
    "                for j in range(len(row['STR'])):\n",
    "                    #assert row['labels'][i + j] == 'O'\n",
    "                    if row['labels'][i + j] != 'O':\n",
    "                        OVERLAP_IDX.add(row['id'])\n",
    "                    if len(row['STR']) == 1:       row['labels'][i + j] = 'S-STR'\n",
    "                    elif j == 0:                   row['labels'][i + j] = 'B-STR'\n",
    "                    elif j == len(row['STR']) - 1: row['labels'][i + j] = 'E-STR'\n",
    "                    else:                          row['labels'][i + j] = 'I-STR'\n",
    "                    if row['strip_tokens'][i + j] != row['STR'][j]:\n",
    "                        row['full_tokens'][i + j] = row['full_tokens'][i + j].replace(row['strip_tokens'][i + j], row['STR'][j])\n",
    "                        row['labels'][i + j] += '-SHORT'\n",
    "                        shorten = True\n",
    "                        if not row['strip_tokens'][i + j] in wordlist_raw: wordlist_raw[row['strip_tokens'][i + j]] = {}\n",
    "                        if not row['STR'][j] in wordlist_raw[row['strip_tokens'][i + j]]: wordlist_raw[row['strip_tokens'][i + j]][row['STR'][j]] = 0\n",
    "                        wordlist_raw[row['strip_tokens'][i + j]][row['STR'][j]] += 1\n",
    "    \n",
    "    if len(row['POI']) > 0 and not found_poi:\n",
    "        POI_ERR_IDX.append(row['id'])\n",
    "    if len(row['STR']) > 0 and not found_str:\n",
    "        STR_ERR_IDX.append(row['id'])\n",
    "    if shorten:\n",
    "        SHORTEN_IDX.append(row['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11825, 196, 96, 59011, 919)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(wordlist_raw), len(POI_ERR_IDX), len(STR_ERR_IDX), len(SHORTEN_IDX), len(OVERLAP_IDX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>raw_address</th>\n",
       "      <th>POI/street</th>\n",
       "      <th>POI</th>\n",
       "      <th>STR</th>\n",
       "      <th>tokens</th>\n",
       "      <th>strip_tokens</th>\n",
       "      <th>full_tokens</th>\n",
       "      <th>labels</th>\n",
       "      <th>pos_poi</th>\n",
       "      <th>pos_str</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>cikahuripan sd neg boj 02 klap boj, no 5 16877</td>\n",
       "      <td>sd negeri bojong 02/klap boj</td>\n",
       "      <td>[sd, negeri, bojong, 02]</td>\n",
       "      <td>[klap, boj]</td>\n",
       "      <td>[cikahuripan, sd, neg, boj, 02, klap, boj,, no...</td>\n",
       "      <td>[cikahuripan, sd, neg, boj, 02, klap, boj, no,...</td>\n",
       "      <td>[cikahuripan, sd, negeri, bojong, 02, klap, bo...</td>\n",
       "      <td>[O, B-POI, I-POI-SHORT, I-POI-SHORT, E-POI, B-...</td>\n",
       "      <td>[1, 4]</td>\n",
       "      <td>[5, 6]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>yaya atohar,</td>\n",
       "      <td>yayasan atohariyah/</td>\n",
       "      <td>[yayasan, atohariyah]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[yaya, atohar,]</td>\n",
       "      <td>[yaya, atohar]</td>\n",
       "      <td>[yayasan, atohariyah,]</td>\n",
       "      <td>[B-POI-SHORT, E-POI-SHORT]</td>\n",
       "      <td>[0, 1]</td>\n",
       "      <td>[-1, -1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>toko bang ajs,</td>\n",
       "      <td>toko bangunan ajs/</td>\n",
       "      <td>[toko, bangunan, ajs]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[toko, bang, ajs,]</td>\n",
       "      <td>[toko, bang, ajs]</td>\n",
       "      <td>[toko, bangunan, ajs,]</td>\n",
       "      <td>[B-POI, I-POI-SHORT, E-POI]</td>\n",
       "      <td>[0, 2]</td>\n",
       "      <td>[-1, -1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>40</td>\n",
       "      <td>mar tabl metro iringmulyo metro timur</td>\n",
       "      <td>markaz tabligh metro/</td>\n",
       "      <td>[markaz, tabligh, metro]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[mar, tabl, metro, iringmulyo, metro, timur]</td>\n",
       "      <td>[mar, tabl, metro, iringmulyo, metro, timur]</td>\n",
       "      <td>[markaz, tabligh, metro, iringmulyo, metro, ti...</td>\n",
       "      <td>[B-POI-SHORT, I-POI-SHORT, E-POI, O, O, O]</td>\n",
       "      <td>[0, 2]</td>\n",
       "      <td>[-1, -1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>44</td>\n",
       "      <td>sd neg 12 anggrek</td>\n",
       "      <td>sd negeri 12 anggrek/</td>\n",
       "      <td>[sd, negeri, 12, anggrek]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[sd, neg, 12, anggrek]</td>\n",
       "      <td>[sd, neg, 12, anggrek]</td>\n",
       "      <td>[sd, negeri, 12, anggrek]</td>\n",
       "      <td>[B-POI, I-POI-SHORT, I-POI, E-POI]</td>\n",
       "      <td>[0, 3]</td>\n",
       "      <td>[-1, -1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>48</td>\n",
       "      <td>rumah makan pela, raya jomb,</td>\n",
       "      <td>rumah makan pelangi/raya jomb</td>\n",
       "      <td>[rumah, makan, pelangi]</td>\n",
       "      <td>[raya, jomb]</td>\n",
       "      <td>[rumah, makan, pela,, raya, jomb,]</td>\n",
       "      <td>[rumah, makan, pela, raya, jomb]</td>\n",
       "      <td>[rumah, makan, pelangi,, raya, jomb,]</td>\n",
       "      <td>[B-POI, I-POI, E-POI-SHORT, B-STR, E-STR]</td>\n",
       "      <td>[0, 2]</td>\n",
       "      <td>[3, 4]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>69</td>\n",
       "      <td>cak 11 nagasari karawang barat</td>\n",
       "      <td>/cakrad</td>\n",
       "      <td>[]</td>\n",
       "      <td>[cakrad]</td>\n",
       "      <td>[cak, 11, nagasari, karawang, barat]</td>\n",
       "      <td>[cak, 11, nagasari, karawang, barat]</td>\n",
       "      <td>[cakrad, 11, nagasari, karawang, barat]</td>\n",
       "      <td>[S-STR-SHORT, O, O, O, O]</td>\n",
       "      <td>[-1, -1]</td>\n",
       "      <td>[0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>74</td>\n",
       "      <td>rnd prin, gang pinak, sukarame</td>\n",
       "      <td>rnd printing/gang pinak</td>\n",
       "      <td>[rnd, printing]</td>\n",
       "      <td>[gang, pinak]</td>\n",
       "      <td>[rnd, prin,, gang, pinak,, sukarame]</td>\n",
       "      <td>[rnd, prin, gang, pinak, sukarame]</td>\n",
       "      <td>[rnd, printing,, gang, pinak,, sukarame]</td>\n",
       "      <td>[B-POI, E-POI-SHORT, B-STR, E-STR, O]</td>\n",
       "      <td>[0, 1]</td>\n",
       "      <td>[2, 3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>76</td>\n",
       "      <td>pp minhajutt, kh abdul manan, sumberberas muncar</td>\n",
       "      <td>pp minhajutthollab/kh abdul manan</td>\n",
       "      <td>[pp, minhajutthollab]</td>\n",
       "      <td>[kh, abdul, manan]</td>\n",
       "      <td>[pp, minhajutt,, kh, abdul, manan,, sumberbera...</td>\n",
       "      <td>[pp, minhajutt, kh, abdul, manan, sumberberas,...</td>\n",
       "      <td>[pp, minhajutthollab,, kh, abdul, manan,, sumb...</td>\n",
       "      <td>[B-POI, E-POI-SHORT, B-STR, I-STR, E-STR, O, O]</td>\n",
       "      <td>[0, 1]</td>\n",
       "      <td>[2, 4]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>77</td>\n",
       "      <td>tk islam daruss,</td>\n",
       "      <td>tk islam darussalam/</td>\n",
       "      <td>[tk, islam, darussalam]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[tk, islam, daruss,]</td>\n",
       "      <td>[tk, islam, daruss]</td>\n",
       "      <td>[tk, islam, darussalam,]</td>\n",
       "      <td>[B-POI, I-POI, E-POI-SHORT]</td>\n",
       "      <td>[0, 2]</td>\n",
       "      <td>[-1, -1]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id                                       raw_address  \\\n",
       "10  10    cikahuripan sd neg boj 02 klap boj, no 5 16877   \n",
       "11  11                                      yaya atohar,   \n",
       "20  20                                    toko bang ajs,   \n",
       "40  40             mar tabl metro iringmulyo metro timur   \n",
       "44  44                                 sd neg 12 anggrek   \n",
       "48  48                      rumah makan pela, raya jomb,   \n",
       "69  69                    cak 11 nagasari karawang barat   \n",
       "74  74                    rnd prin, gang pinak, sukarame   \n",
       "76  76  pp minhajutt, kh abdul manan, sumberberas muncar   \n",
       "77  77                                  tk islam daruss,   \n",
       "\n",
       "                           POI/street                        POI  \\\n",
       "10       sd negeri bojong 02/klap boj   [sd, negeri, bojong, 02]   \n",
       "11                yayasan atohariyah/      [yayasan, atohariyah]   \n",
       "20                 toko bangunan ajs/      [toko, bangunan, ajs]   \n",
       "40              markaz tabligh metro/   [markaz, tabligh, metro]   \n",
       "44              sd negeri 12 anggrek/  [sd, negeri, 12, anggrek]   \n",
       "48      rumah makan pelangi/raya jomb    [rumah, makan, pelangi]   \n",
       "69                            /cakrad                         []   \n",
       "74            rnd printing/gang pinak            [rnd, printing]   \n",
       "76  pp minhajutthollab/kh abdul manan      [pp, minhajutthollab]   \n",
       "77               tk islam darussalam/    [tk, islam, darussalam]   \n",
       "\n",
       "                   STR                                             tokens  \\\n",
       "10         [klap, boj]  [cikahuripan, sd, neg, boj, 02, klap, boj,, no...   \n",
       "11                  []                                    [yaya, atohar,]   \n",
       "20                  []                                 [toko, bang, ajs,]   \n",
       "40                  []       [mar, tabl, metro, iringmulyo, metro, timur]   \n",
       "44                  []                             [sd, neg, 12, anggrek]   \n",
       "48        [raya, jomb]                 [rumah, makan, pela,, raya, jomb,]   \n",
       "69            [cakrad]               [cak, 11, nagasari, karawang, barat]   \n",
       "74       [gang, pinak]               [rnd, prin,, gang, pinak,, sukarame]   \n",
       "76  [kh, abdul, manan]  [pp, minhajutt,, kh, abdul, manan,, sumberbera...   \n",
       "77                  []                               [tk, islam, daruss,]   \n",
       "\n",
       "                                         strip_tokens  \\\n",
       "10  [cikahuripan, sd, neg, boj, 02, klap, boj, no,...   \n",
       "11                                     [yaya, atohar]   \n",
       "20                                  [toko, bang, ajs]   \n",
       "40       [mar, tabl, metro, iringmulyo, metro, timur]   \n",
       "44                             [sd, neg, 12, anggrek]   \n",
       "48                   [rumah, makan, pela, raya, jomb]   \n",
       "69               [cak, 11, nagasari, karawang, barat]   \n",
       "74                 [rnd, prin, gang, pinak, sukarame]   \n",
       "76  [pp, minhajutt, kh, abdul, manan, sumberberas,...   \n",
       "77                                [tk, islam, daruss]   \n",
       "\n",
       "                                          full_tokens  \\\n",
       "10  [cikahuripan, sd, negeri, bojong, 02, klap, bo...   \n",
       "11                             [yayasan, atohariyah,]   \n",
       "20                             [toko, bangunan, ajs,]   \n",
       "40  [markaz, tabligh, metro, iringmulyo, metro, ti...   \n",
       "44                          [sd, negeri, 12, anggrek]   \n",
       "48              [rumah, makan, pelangi,, raya, jomb,]   \n",
       "69            [cakrad, 11, nagasari, karawang, barat]   \n",
       "74           [rnd, printing,, gang, pinak,, sukarame]   \n",
       "76  [pp, minhajutthollab,, kh, abdul, manan,, sumb...   \n",
       "77                           [tk, islam, darussalam,]   \n",
       "\n",
       "                                               labels   pos_poi   pos_str  \n",
       "10  [O, B-POI, I-POI-SHORT, I-POI-SHORT, E-POI, B-...    [1, 4]    [5, 6]  \n",
       "11                         [B-POI-SHORT, E-POI-SHORT]    [0, 1]  [-1, -1]  \n",
       "20                        [B-POI, I-POI-SHORT, E-POI]    [0, 2]  [-1, -1]  \n",
       "40         [B-POI-SHORT, I-POI-SHORT, E-POI, O, O, O]    [0, 2]  [-1, -1]  \n",
       "44                 [B-POI, I-POI-SHORT, I-POI, E-POI]    [0, 3]  [-1, -1]  \n",
       "48          [B-POI, I-POI, E-POI-SHORT, B-STR, E-STR]    [0, 2]    [3, 4]  \n",
       "69                          [S-STR-SHORT, O, O, O, O]  [-1, -1]    [0, 0]  \n",
       "74              [B-POI, E-POI-SHORT, B-STR, E-STR, O]    [0, 1]    [2, 3]  \n",
       "76    [B-POI, E-POI-SHORT, B-STR, I-STR, E-STR, O, O]    [0, 1]    [2, 4]  \n",
       "77                        [B-POI, I-POI, E-POI-SHORT]    [0, 2]  [-1, -1]  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sanity check\n",
    "train_df[train_df['id'].isin(SHORTEN_IDX[:10])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1211"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ERR_IDX = set(POI_ERR_IDX + STR_ERR_IDX + list(OVERLAP_IDX))\n",
    "len(ERR_IDX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df[~train_df['id'].isin(ERR_IDX)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanshort(arr):\n",
    "    return [s.replace('-SHORT', '') for s in arr]\n",
    "\n",
    "new_train_df = train_df[train_df['id'].isin(SHORTEN_IDX)].copy(deep=True)\n",
    "new_train_df['tokens'] = new_train_df['full_tokens'].apply(dummy)\n",
    "new_train_df['labels'] = new_train_df['labels'].apply(cleanshort)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>raw_address</th>\n",
       "      <th>POI/street</th>\n",
       "      <th>POI</th>\n",
       "      <th>STR</th>\n",
       "      <th>tokens</th>\n",
       "      <th>strip_tokens</th>\n",
       "      <th>full_tokens</th>\n",
       "      <th>labels</th>\n",
       "      <th>pos_poi</th>\n",
       "      <th>pos_str</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>cikahuripan sd neg boj 02 klap boj, no 5 16877</td>\n",
       "      <td>sd negeri bojong 02/klap boj</td>\n",
       "      <td>[sd, negeri, bojong, 02]</td>\n",
       "      <td>[klap, boj]</td>\n",
       "      <td>[cikahuripan, sd, negeri, bojong, 02, klap, bo...</td>\n",
       "      <td>[cikahuripan, sd, neg, boj, 02, klap, boj, no,...</td>\n",
       "      <td>[cikahuripan, sd, negeri, bojong, 02, klap, bo...</td>\n",
       "      <td>[O, B-POI, I-POI, I-POI, E-POI, B-STR, E-STR, ...</td>\n",
       "      <td>[1, 4]</td>\n",
       "      <td>[5, 6]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>yaya atohar,</td>\n",
       "      <td>yayasan atohariyah/</td>\n",
       "      <td>[yayasan, atohariyah]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[yayasan, atohariyah,]</td>\n",
       "      <td>[yaya, atohar]</td>\n",
       "      <td>[yayasan, atohariyah,]</td>\n",
       "      <td>[B-POI, E-POI]</td>\n",
       "      <td>[0, 1]</td>\n",
       "      <td>[-1, -1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>toko bang ajs,</td>\n",
       "      <td>toko bangunan ajs/</td>\n",
       "      <td>[toko, bangunan, ajs]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[toko, bangunan, ajs,]</td>\n",
       "      <td>[toko, bang, ajs]</td>\n",
       "      <td>[toko, bangunan, ajs,]</td>\n",
       "      <td>[B-POI, I-POI, E-POI]</td>\n",
       "      <td>[0, 2]</td>\n",
       "      <td>[-1, -1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>40</td>\n",
       "      <td>mar tabl metro iringmulyo metro timur</td>\n",
       "      <td>markaz tabligh metro/</td>\n",
       "      <td>[markaz, tabligh, metro]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[markaz, tabligh, metro, iringmulyo, metro, ti...</td>\n",
       "      <td>[mar, tabl, metro, iringmulyo, metro, timur]</td>\n",
       "      <td>[markaz, tabligh, metro, iringmulyo, metro, ti...</td>\n",
       "      <td>[B-POI, I-POI, E-POI, O, O, O]</td>\n",
       "      <td>[0, 2]</td>\n",
       "      <td>[-1, -1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>44</td>\n",
       "      <td>sd neg 12 anggrek</td>\n",
       "      <td>sd negeri 12 anggrek/</td>\n",
       "      <td>[sd, negeri, 12, anggrek]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[sd, negeri, 12, anggrek]</td>\n",
       "      <td>[sd, neg, 12, anggrek]</td>\n",
       "      <td>[sd, negeri, 12, anggrek]</td>\n",
       "      <td>[B-POI, I-POI, I-POI, E-POI]</td>\n",
       "      <td>[0, 3]</td>\n",
       "      <td>[-1, -1]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id                                     raw_address  \\\n",
       "10  10  cikahuripan sd neg boj 02 klap boj, no 5 16877   \n",
       "11  11                                    yaya atohar,   \n",
       "20  20                                  toko bang ajs,   \n",
       "40  40           mar tabl metro iringmulyo metro timur   \n",
       "44  44                               sd neg 12 anggrek   \n",
       "\n",
       "                      POI/street                        POI          STR  \\\n",
       "10  sd negeri bojong 02/klap boj   [sd, negeri, bojong, 02]  [klap, boj]   \n",
       "11           yayasan atohariyah/      [yayasan, atohariyah]           []   \n",
       "20            toko bangunan ajs/      [toko, bangunan, ajs]           []   \n",
       "40         markaz tabligh metro/   [markaz, tabligh, metro]           []   \n",
       "44         sd negeri 12 anggrek/  [sd, negeri, 12, anggrek]           []   \n",
       "\n",
       "                                               tokens  \\\n",
       "10  [cikahuripan, sd, negeri, bojong, 02, klap, bo...   \n",
       "11                             [yayasan, atohariyah,]   \n",
       "20                             [toko, bangunan, ajs,]   \n",
       "40  [markaz, tabligh, metro, iringmulyo, metro, ti...   \n",
       "44                          [sd, negeri, 12, anggrek]   \n",
       "\n",
       "                                         strip_tokens  \\\n",
       "10  [cikahuripan, sd, neg, boj, 02, klap, boj, no,...   \n",
       "11                                     [yaya, atohar]   \n",
       "20                                  [toko, bang, ajs]   \n",
       "40       [mar, tabl, metro, iringmulyo, metro, timur]   \n",
       "44                             [sd, neg, 12, anggrek]   \n",
       "\n",
       "                                          full_tokens  \\\n",
       "10  [cikahuripan, sd, negeri, bojong, 02, klap, bo...   \n",
       "11                             [yayasan, atohariyah,]   \n",
       "20                             [toko, bangunan, ajs,]   \n",
       "40  [markaz, tabligh, metro, iringmulyo, metro, ti...   \n",
       "44                          [sd, negeri, 12, anggrek]   \n",
       "\n",
       "                                               labels pos_poi   pos_str  \n",
       "10  [O, B-POI, I-POI, I-POI, E-POI, B-STR, E-STR, ...  [1, 4]    [5, 6]  \n",
       "11                                     [B-POI, E-POI]  [0, 1]  [-1, -1]  \n",
       "20                              [B-POI, I-POI, E-POI]  [0, 2]  [-1, -1]  \n",
       "40                     [B-POI, I-POI, E-POI, O, O, O]  [0, 2]  [-1, -1]  \n",
       "44                       [B-POI, I-POI, I-POI, E-POI]  [0, 3]  [-1, -1]  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.append(new_train_df, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "swap_parts = []\n",
    "swap_tokens = []\n",
    "swap_labels = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 357219/357219 [00:59<00:00, 6029.65it/s]\n"
     ]
    }
   ],
   "source": [
    "for idx in tqdm(range(len(train_df))):\n",
    "    old_row = train_df.iloc[idx]\n",
    "    if old_row['pos_poi'][0] == -1 or old_row['pos_str'][0] == -1: continue\n",
    "    \n",
    "    start_poi, end_poi = old_row['pos_poi']\n",
    "    start_str, end_str = old_row['pos_str']\n",
    "    if end_poi < start_str:\n",
    "        swap_tokens.append(old_row['tokens'][:start_poi] + \\\n",
    "                           old_row['tokens'][start_str:end_str + 1] + \\\n",
    "                           old_row['tokens'][end_poi + 1:start_str] + \\\n",
    "                           old_row['tokens'][start_poi:end_poi + 1] + \\\n",
    "                           old_row['tokens'][end_str + 1:])\n",
    "        swap_labels.append(old_row['labels'][:start_poi] + \\\n",
    "                           old_row['labels'][start_str:end_str + 1] + \\\n",
    "                           old_row['labels'][end_poi + 1:start_str] + \\\n",
    "                           old_row['labels'][start_poi:end_poi + 1] + \\\n",
    "                           old_row['labels'][end_str + 1:])\n",
    "        swap_parts.append((0, \\\n",
    "                           old_row['tokens'][:start_poi], \\\n",
    "                           old_row['tokens'][start_str:end_str + 1], \\\n",
    "                           old_row['tokens'][end_poi + 1:start_str], \\\n",
    "                           old_row['tokens'][start_poi:end_poi + 1], \\\n",
    "                           old_row['tokens'][end_str + 1:], \\\n",
    "                           old_row['labels'][:start_poi], \\\n",
    "                           old_row['labels'][start_str:end_str + 1], \\\n",
    "                           old_row['labels'][end_poi + 1:start_str], \\\n",
    "                           old_row['labels'][start_poi:end_poi + 1], \\\n",
    "                           old_row['labels'][end_str + 1:]))\n",
    "    else:\n",
    "        swap_tokens.append(old_row['tokens'][:start_str] + \\\n",
    "                           old_row['tokens'][start_poi:end_poi + 1] + \\\n",
    "                           old_row['tokens'][end_str + 1:start_poi] + \\\n",
    "                           old_row['tokens'][start_str:end_str + 1] + \\\n",
    "                           old_row['tokens'][end_poi + 1:])\n",
    "        swap_labels.append(old_row['labels'][:start_str] + \\\n",
    "                           old_row['labels'][start_poi:end_poi + 1] + \\\n",
    "                           old_row['labels'][end_str + 1:start_poi] + \\\n",
    "                           old_row['labels'][start_str:end_str + 1] + \\\n",
    "                           old_row['labels'][end_poi + 1:])\n",
    "        swap_parts.append((1, \\\n",
    "                           old_row['tokens'][:start_str], \\\n",
    "                           old_row['tokens'][start_poi:end_poi + 1], \\\n",
    "                           old_row['tokens'][end_str + 1:start_poi], \\\n",
    "                           old_row['tokens'][start_str:end_str + 1], \\\n",
    "                           old_row['tokens'][end_poi + 1:], \\\n",
    "                           old_row['labels'][:start_str], \\\n",
    "                           old_row['labels'][start_poi:end_poi + 1], \\\n",
    "                           old_row['labels'][end_str + 1:start_poi], \\\n",
    "                           old_row['labels'][start_str:end_str + 1], \\\n",
    "                           old_row['labels'][end_poi + 1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "swap_idx = list(range(len(swap_parts)))\n",
    "random.Random(4).shuffle(swap_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 122193/122193 [00:00<00:00, 205567.12it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(len(swap_parts))):\n",
    "    if i == swap_idx[i]: continue\n",
    "    j = swap_idx[i]\n",
    "    \n",
    "    swap_tokens.append(swap_parts[i][1] + swap_parts[j][2] + swap_parts[i][3] + swap_parts[j][4] + swap_parts[i][5])\n",
    "    swap_labels.append(swap_parts[i][6] + swap_parts[j][7] + swap_parts[i][8] + swap_parts[j][9] + swap_parts[i][10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokens</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[toko, bb, kids, 299, raya, samb, gede,]</td>\n",
       "      <td>[B-POI, I-POI, E-POI, O, B-STR, I-STR, E-STR]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[cikahuripan, klap, boj,, sd, neg, boj, 02, no...</td>\n",
       "      <td>[O, B-STR, E-STR, B-POI, I-POI-SHORT, I-POI-SH...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[br., junjungan,, jln., tirta, tawar,, ubud,, ...</td>\n",
       "      <td>[B-POI, E-POI, B-STR, I-STR, E-STR, O, O, O, O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[komplek, borneo, lestari,, jl., amd,, blok, 2...</td>\n",
       "      <td>[B-POI, I-POI, E-POI, B-STR, E-STR, O, O, O, O]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[raya, jomb,, rumah, makan, pela,]</td>\n",
       "      <td>[B-STR, E-STR, B-POI, I-POI, E-POI-SHORT]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              tokens  \\\n",
       "0           [toko, bb, kids, 299, raya, samb, gede,]   \n",
       "1  [cikahuripan, klap, boj,, sd, neg, boj, 02, no...   \n",
       "2  [br., junjungan,, jln., tirta, tawar,, ubud,, ...   \n",
       "3  [komplek, borneo, lestari,, jl., amd,, blok, 2...   \n",
       "4                 [raya, jomb,, rumah, makan, pela,]   \n",
       "\n",
       "                                              labels  \n",
       "0      [B-POI, I-POI, E-POI, O, B-STR, I-STR, E-STR]  \n",
       "1  [O, B-STR, E-STR, B-POI, I-POI-SHORT, I-POI-SH...  \n",
       "2  [B-POI, E-POI, B-STR, I-STR, E-STR, O, O, O, O...  \n",
       "3    [B-POI, I-POI, E-POI, B-STR, E-STR, O, O, O, O]  \n",
       "4          [B-STR, E-STR, B-POI, I-POI, E-POI-SHORT]  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "swap_train_df = pd.DataFrame(columns=['tokens', 'labels'], data={'tokens': swap_tokens, 'labels': swap_labels})\n",
    "swap_train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.drop(columns=['id', 'raw_address', 'POI/street', 'POI', 'STR', 'strip_tokens', 'full_tokens', 'pos_poi', 'pos_str'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.append(swap_train_df, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokens</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[jl, kapuk, timur, delta, sili, iii, lippo, ci...</td>\n",
       "      <td>[B-STR, I-STR, I-STR, I-STR, I-STR, I-STR, I-S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[aye,, jati, sampurna]</td>\n",
       "      <td>[O, O, O]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[setu, siung, 119, rt, 5, 1, 13880, cipayung]</td>\n",
       "      <td>[O, S-STR, O, O, O, O, O, O]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[toko, dita,, kertosono]</td>\n",
       "      <td>[B-POI, E-POI, O]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[jl., orde, baru]</td>\n",
       "      <td>[B-STR, I-STR, E-STR]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              tokens  \\\n",
       "0  [jl, kapuk, timur, delta, sili, iii, lippo, ci...   \n",
       "1                             [aye,, jati, sampurna]   \n",
       "2      [setu, siung, 119, rt, 5, 1, 13880, cipayung]   \n",
       "3                           [toko, dita,, kertosono]   \n",
       "4                                  [jl., orde, baru]   \n",
       "\n",
       "                                              labels  \n",
       "0  [B-STR, I-STR, I-STR, I-STR, I-STR, I-STR, I-S...  \n",
       "1                                          [O, O, O]  \n",
       "2                       [O, S-STR, O, O, O, O, O, O]  \n",
       "3                                  [B-POI, E-POI, O]  \n",
       "4                              [B-STR, I-STR, E-STR]  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "601605"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv('train-ner-2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('wordlist_raw.json', 'w') as fp:\n",
    "    json.dump(wordlist_raw, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('wordlist_raw.json', 'r') as fp:\n",
    "    wordlist_raw = json.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11825"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(wordlist_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_list(raw, p, lmt):\n",
    "    res = {}\n",
    "    for word, stats in raw.items():\n",
    "        best = max(stats, key=stats.get)\n",
    "        best_cnt = stats[best]\n",
    "        total = sum(stats.values())\n",
    "        frac = best_cnt / total\n",
    "        if total >= lmt and best_cnt / total >= p: \n",
    "            res[word] = best\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordlist = get_list(wordlist_raw, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11825"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(wordlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('wordlist.json', 'w') as fp:\n",
    "    json.dump(wordlist, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('wordlist.json', 'r') as fp:\n",
    "    wordlist = json.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11825"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(wordlist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from transformers import *\n",
    "from fastai.text.all import *\n",
    "\n",
    "from blurr.data.all import *\n",
    "from blurr.modeling.all import *\n",
    "\n",
    "SEED = 42\n",
    "set_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B-POI', 'B-POI-SHORT', 'B-STR', 'B-STR-SHORT', 'E-POI', 'E-POI-SHORT', 'E-STR', 'E-STR-SHORT', 'I-POI', 'I-POI-SHORT', 'I-STR', 'I-STR-SHORT', 'O', 'S-POI', 'S-POI-SHORT', 'S-STR', 'S-STR-SHORT']\n"
     ]
    }
   ],
   "source": [
    "labels = sorted(list(set([lbls for sublist in train_df.labels.tolist() for lbls in sublist])))\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('bert',\n",
       " transformers.models.bert.configuration_bert.BertConfig,\n",
       " transformers.models.bert.tokenization_bert_fast.BertTokenizerFast,\n",
       " transformers.models.bert.modeling_bert.BertForTokenClassification)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task = HF_TASKS_AUTO.TokenClassification\n",
    "# pretrained_model_name = 'bert-base-multilingual-uncased'\n",
    "pretrained_model_name = 'indobenchmark/indobert-large-p1'\n",
    "config = AutoConfig.from_pretrained(pretrained_model_name)\n",
    "config.num_labels = len(labels)\n",
    "\n",
    "hf_arch, hf_config, hf_tokenizer, hf_model = BLURR_MODEL_HELPER.get_hf_objects(pretrained_model_name, \n",
    "                                                                               task=task, \n",
    "                                                                               config=config)\n",
    "hf_arch, type(hf_config), type(hf_tokenizer), type(hf_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "before_batch_tfm = HF_TokenClassBeforeBatchTransform(hf_arch, hf_config, hf_tokenizer, hf_model,\n",
    "                                                     is_split_into_words=True, \n",
    "                                                     tok_kwargs={ 'return_special_tokens_mask': True })\n",
    "\n",
    "blocks = (\n",
    "    HF_TextBlock(before_batch_tfm=before_batch_tfm, input_return_type=HF_TokenClassInput), \n",
    "    HF_TokenCategoryBlock(vocab=labels)\n",
    ")\n",
    "\n",
    "def get_y(inp): return [(label, len(hf_tokenizer.tokenize(str(entity)))) for entity, label in zip(inp.tokens, inp.labels)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = DataBlock(blocks=blocks, \n",
    "               splitter=RandomSplitter(seed=42),\n",
    "               get_x=ColReader('tokens'),\n",
    "               get_y=get_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token / target label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[('dusun', 'B-POI'), ('7', 'I-POI'), ('1', 'I-POI'), ('=', 'I-POI'), ('c', 'I-POI'), ('dalam', 'I-POI'), ('patokan', 'I-POI'), ('masuk', 'I-POI'), ('dari', 'I-POI'), ('pasar', 'I-POI'), ('1', 'I-POI'), ('paya', 'E-POI'), ('bakung', 'O'), ('masuk,', 'O'), ('sumber', 'O'), ('melati', 'B-STR'), ('diski', 'I-STR'), ('jl', 'I-STR'), ('imp', 'I-STR'), ('sebe', 'I-STR'), ('mush', 'I-STR'), ('bau', 'I-STR'), ('muk', 'I-STR'), ('di', 'I-STR'), ('ping', 'I-STR'), ('sun', 'I-STR'), ('kecil', 'I-STR'), ('buka', 'I-STR'), ('08.', 'E-STR'), ('00', 'O')]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[('swadaya', 'O'), ('dalam', 'O'), ('no', 'O'), (':', 'O'), ('31', 'O'), ('rt', 'O'), (':', 'O'), ('05', 'O'), ('rw', 'O'), (':', 'O'), ('06', 'O'), ('cawang', 'O'), ('kapling', 'O'), ('-', 'O'), ('tanah', 'O'), ('manisan', 'O'), ('-', 'O'), ('jakarta', 'O'), ('-', 'O'), ('timur', 'O')]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[('baba', 'B-STR'), ('sayu', 'I-STR'), ('gg', 'I-STR'), ('sete', 'I-STR'), ('pasar', 'I-STR'), ('sayung', 'I-STR'), ('dari', 'I-STR'), ('sema', 'I-STR'), ('kanan,', 'E-STR'), ('sayung', 'O'), ('toko', 'B-POI'), ('arsya', 'I-POI'), ('pak', 'I-POI'), ('suwarno', 'I-POI'), ('sayung', 'I-POI'), ('wetan', 'E-POI'), ('rt', 'O'), ('5', 'O'), ('1', 'O'), ('sayung', 'O')]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[('sate', 'B-POI'), ('ayam', 'I-POI'), ('dan', 'I-POI'), ('kambing', 'I-POI'), ('pak', 'I-POI'), ('de', 'I-POI'), ('cabang', 'I-POI'), ('gad', 'I-POI-SHORT'), ('serpong,', 'E-POI'), ('no', 'O'), ('a', 'O'), ('15', 'O'), ('boulevard', 'B-STR'), ('raya', 'I-STR'), ('gad', 'I-STR'), ('serp,', 'E-STR'), ('kelapa', 'O'), ('dua', 'O'), ('kelapa', 'O'), ('dua', 'O')]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[('pang', 'B-STR'), ('anta,', 'E-STR'), ('east', 'B-POI'), ('kalimantan', 'I-POI'), ('center', 'I-POI'), ('-', 'I-POI'), ('pusat', 'I-POI'), ('oleh', 'I-POI'), ('-', 'E-POI'), ('oleh', 'O'), ('-', 'O'), ('kaltim,', 'O'), ('lorong', 'O'), ('a', 'O'), ('no.', 'O'), ('63', 'O'), ('rt006', 'O'), ('rw09,', 'O'), ('koja,', 'O')]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[('jl.', 'B-STR'), ('mayor', 'I-STR'), ('salim', 'I-STR'), ('batubara', 'E-STR'), ('d.', 'B-POI'), ('i,', 'E-POI'), ('no.', 'O'), ('6452,', 'O'), ('20', 'O'), ('ilir', 'O'), ('d', 'O'), ('ii,', 'O'), ('kec.', 'O'), ('ilir', 'O'), ('tim.', 'O'), ('i,', 'O'), ('kota', 'O'), ('palembang,', 'O'), ('su', 'O')]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[('ycab', 'O'), ('foundation,', 'O'), ('kedai', 'B-POI'), ('pak', 'I-POI'), ('waji', 'I-POI'), ('dari', 'I-POI'), ('jam', 'I-POI'), ('7', 'I-POI'), ('-', 'E-POI'), ('10', 'B-STR'), ('malam', 'I-STR'), ('jl.', 'I-STR'), ('r', 'I-STR'), ('panj', 'I-STR'), ('oku', 'I-STR'), ('dekat', 'E-STR'), ('sd', 'O'), ('016', 'O'), ('no', 'O')]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[('rawa', 'O'), ('buaya', 'O'), ('ruko', 'O'), ('inter', 'O'), ('kota', 'O'), ('blok', 'O'), (':', 'O'), ('no', 'O'), ('b', 'O'), ('8', 'O'), ('rt', 'O'), ('rw', 'O'), ('07', 'O'), ('09', 'O'), ('sebrang', 'B-POI'), ('gedung', 'E-POI'), ('ot', 'O'), ('samping', 'O'), ('charllie', 'O')]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[('rental', 'B-POI'), ('mobil', 'I-POI'), ('sutikno', 'I-POI'), ('pekarungan', 'E-POI'), ('pekarungan', 'O'), ('nan', 'B-STR'), ('iii,', 'I-STR'), ('gg', 'I-STR'), ('tam', 'I-STR'), ('sari', 'I-STR'), ('suko', 'I-STR'), ('sido', 'I-STR'), ('jawa', 'I-STR'), ('timur', 'I-STR'), ('indo', 'E-STR'), ('rt', 'O'), ('11', 'O'), ('4', 'O'), ('sukodono', 'O')]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dls = db.dataloaders(train_df, bs=128)\n",
    "dls.show_batch(dataloaders=dls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "@delegates()\n",
    "class TokenCrossEntropyLossFlat(BaseLoss):\n",
    "    \"Same as `CrossEntropyLossFlat`, but for mutiple tokens output\"\n",
    "    y_int = True\n",
    "    @use_kwargs_dict(keep=True, weight=None, ignore_index=-100, reduction='mean')\n",
    "    def __init__(self, *args, axis=-1, **kwargs): super().__init__(nn.CrossEntropyLoss, *args, axis=axis, **kwargs)\n",
    "    def decodes(self, x):    return L([ i.argmax(dim=self.axis) for i in x ])\n",
    "    def activation(self, x): return L([ F.softmax(i, dim=self.axis) for i in x ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = HF_BaseModelWrapper(hf_model)\n",
    "loss_func = TokenCrossEntropyLossFlat()\n",
    "opt_func = partial(Adam)\n",
    "learn_cbs = [HF_BaseModelCallback]\n",
    "fit_cbs = [HF_TokenClassMetricsCallback()]\n",
    "splitter = hf_splitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn1 = Learner(dls, model, loss_func=loss_func, opt_func=opt_func, splitter=splitter, cbs=learn_cbs).to_fp16()\n",
    "learn2 = Learner(dls, model, loss_func=loss_func, opt_func=opt_func, splitter=splitter, cbs=learn_cbs).to_fp16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn1.create_opt()\n",
    "learn2.create_opt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn1.unfreeze()\n",
    "learn2.unfreeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.347030</td>\n",
       "      <td>0.363953</td>\n",
       "      <td>0.894492</td>\n",
       "      <td>0.779272</td>\n",
       "      <td>0.714002</td>\n",
       "      <td>0.745211</td>\n",
       "      <td>12:20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.259750</td>\n",
       "      <td>0.255239</td>\n",
       "      <td>0.929252</td>\n",
       "      <td>0.844856</td>\n",
       "      <td>0.834800</td>\n",
       "      <td>0.839798</td>\n",
       "      <td>12:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.213813</td>\n",
       "      <td>0.225695</td>\n",
       "      <td>0.938303</td>\n",
       "      <td>0.870825</td>\n",
       "      <td>0.855771</td>\n",
       "      <td>0.863233</td>\n",
       "      <td>12:20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.167972</td>\n",
       "      <td>0.216481</td>\n",
       "      <td>0.943253</td>\n",
       "      <td>0.884420</td>\n",
       "      <td>0.868227</td>\n",
       "      <td>0.876249</td>\n",
       "      <td>12:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.148400</td>\n",
       "      <td>0.223286</td>\n",
       "      <td>0.944264</td>\n",
       "      <td>0.886923</td>\n",
       "      <td>0.871760</td>\n",
       "      <td>0.879276</td>\n",
       "      <td>12:21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "learn1.fit_one_cycle(5, 1e-4, moms=(0.8, 0.7, 0.8), cbs=fit_cbs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='4' class='' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      80.00% [4/5 1:31:17<22:49]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.310868</td>\n",
       "      <td>0.309791</td>\n",
       "      <td>0.916442</td>\n",
       "      <td>0.814347</td>\n",
       "      <td>0.797192</td>\n",
       "      <td>0.805678</td>\n",
       "      <td>22:56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.235226</td>\n",
       "      <td>0.239664</td>\n",
       "      <td>0.935117</td>\n",
       "      <td>0.866598</td>\n",
       "      <td>0.846518</td>\n",
       "      <td>0.856440</td>\n",
       "      <td>22:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.204660</td>\n",
       "      <td>0.211123</td>\n",
       "      <td>0.943851</td>\n",
       "      <td>0.884705</td>\n",
       "      <td>0.869180</td>\n",
       "      <td>0.876874</td>\n",
       "      <td>22:49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.157571</td>\n",
       "      <td>0.204892</td>\n",
       "      <td>0.947870</td>\n",
       "      <td>0.899703</td>\n",
       "      <td>0.880835</td>\n",
       "      <td>0.890169</td>\n",
       "      <td>22:33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='1815' class='' max='3760' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      48.27% [1815/3760 07:29<08:02 0.1164]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn2.fit_one_cycle(5, 1e-4, moms=(0.8, 0.7, 0.8), cbs=fit_cbs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn1.recorder.plot_loss()\n",
    "learn2.recorder.plot_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(learn1.token_classification_report)\n",
    "print(learn2.token_classification_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn1.save('bert-multi-2')\n",
    "learn2.save('bert-indo-2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<fastai.learner.Learner at 0x7f4dec2aecd0>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn1.load('bert-multi-2')\n",
    "learn2.load('bert-indo-2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "@patch\n",
    "def blurr_predict(self:Learner, items, rm_type_tfms=None):\n",
    "    hf_before_batch_tfm = get_blurr_tfm(self.dls.before_batch)\n",
    "    is_split_str = hf_before_batch_tfm.is_split_into_words and isinstance(items[0], str)\n",
    "    is_df = isinstance(items, pd.DataFrame)\n",
    "    if (not is_df and (is_split_str or not is_listy(items))): items = [items]\n",
    "    dl = self.dls.test_dl(items, rm_type_tfms=rm_type_tfms, num_workers=0)\n",
    "    with self.no_bar(): probs, _, decoded_preds = self.get_preds(dl=dl, with_input=False, with_decoded=True)\n",
    "    trg_tfms = self.dls.tfms[self.dls.n_inp:]\n",
    "    outs = []\n",
    "    probs, decoded_preds = L(probs), L(decoded_preds)\n",
    "    for i in range(len(items)):\n",
    "        item_probs = [probs[i]]\n",
    "        item_dec_preds = [decoded_preds[i]]\n",
    "        item_dec_labels = tuplify([tfm.decode(item_dec_preds[tfm_idx]) for tfm_idx, tfm in enumerate(trg_tfms)])\n",
    "        outs.append((item_dec_labels, item_dec_preds, item_probs))\n",
    "    return outs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from string import punctuation\n",
    "\n",
    "def reconstruct(num, pred, raw_tokens, raw_address):\n",
    "    def complete_word(x):\n",
    "        y = x.strip().strip(punctuation)\n",
    "        if y in wordlist:\n",
    "            x = x.replace(y, wordlist[y])\n",
    "        return x\n",
    "    \n",
    "    def normalize_bracket(x):\n",
    "        if '(' in x and ')' not in x:\n",
    "            x = x + ')'\n",
    "        elif ')' in x and '(' not in x:\n",
    "            x = '(' + x\n",
    "        return x\n",
    "    \n",
    "    ans = ['/'] * num\n",
    "    for idx in range(num):\n",
    "        res = pred[idx]\n",
    "        start_poi, end_poi = -1, -1\n",
    "        start_str, end_str = -1, -1\n",
    "        for i in range(len(res[0])):\n",
    "            if 'POI' in res[1][i]:\n",
    "                if start_poi == -1: start_poi = i\n",
    "                end_poi = i\n",
    "            if 'STR' in res[1][i]:\n",
    "                if start_str == -1: start_str = i\n",
    "                end_str = i\n",
    "        \n",
    "        if start_poi != -1:\n",
    "            txt1 = raw_address[idx]\n",
    "            for i in range(start_poi):\n",
    "                txt1 = txt1[len(raw_tokens[idx][i]):].strip()\n",
    "            for i in range(len(raw_tokens[idx]) - 1, end_poi, -1):\n",
    "                txt1 = txt1[:-len(raw_tokens[idx][i])].strip()\n",
    "            \n",
    "            txt1_check = ''.join(raw_tokens[idx][start_poi:end_poi + 1]).replace(' ', '')\n",
    "            assert txt1.replace(' ', '') == txt1_check\n",
    "            \n",
    "            last = len(txt1)\n",
    "            for i in range(end_poi, start_poi - 1, -1):\n",
    "                while last > 0 and txt1[last - 1] == ' ':\n",
    "                    last -= 1\n",
    "                assert last >= len(raw_tokens[idx][i])\n",
    "                last -= len(raw_tokens[idx][i])\n",
    "                if 'SHORT' in res[1][i]:\n",
    "                    txt1 = txt1[:last] + complete_word(raw_tokens[idx][i]) + txt1[last + len(raw_tokens[idx][i]):]\n",
    "        else:\n",
    "            txt1 = ''\n",
    "        \n",
    "        if start_str != -1:\n",
    "            txt2 = raw_address[idx]\n",
    "            for i in range(start_str):\n",
    "                txt2 = txt2[len(raw_tokens[idx][i]):].strip()\n",
    "            for i in range(len(raw_tokens[idx]) - 1, end_str, -1):\n",
    "                txt2 = txt2[:-len(raw_tokens[idx][i])].strip()\n",
    "            \n",
    "            txt2_check = ''.join(raw_tokens[idx][start_str:end_str + 1]).replace(' ', '')\n",
    "            assert txt2.replace(' ', '') == txt2_check\n",
    "            \n",
    "            last = len(txt2)\n",
    "            for i in range(end_str, start_str - 1, -1):\n",
    "                while last > 0 and txt2[last - 1] == ' ':\n",
    "                    last -= 1\n",
    "                assert last >= len(raw_tokens[idx][i])\n",
    "                last -= len(raw_tokens[idx][i])\n",
    "                if 'SHORT' in res[1][i]:\n",
    "                    txt2 = txt2[:last] + complete_word(raw_tokens[idx][i]) + txt2[last + len(raw_tokens[idx][i]):]\n",
    "        else:\n",
    "            txt2 = ''\n",
    "        \n",
    "        txt1 = txt1.strip(punctuation)\n",
    "        txt2 = txt2.strip(punctuation)\n",
    "        txt1 = normalize_bracket(txt1)\n",
    "        txt2 = normalize_bracket(txt2)\n",
    "        \n",
    "        ans[idx] = (txt1 + '/' + txt2)\n",
    "    \n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_diff(df):\n",
    "    MAX_ROWS = 50\n",
    "    CNT = 0\n",
    "    for idx in range(len(df)):\n",
    "        if CNT == MAX_ROWS: break\n",
    "        row = df.iloc[idx]\n",
    "        if row['POI/street'] != row['pred']:\n",
    "            CNT += 1\n",
    "            print(idx, row['id'], row['POI/street'], 'vs', row['pred'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_acc(df):\n",
    "    return df.loc[test_df['pred'] == df['POI/street'], 'id'].count() / len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_tokens = list(test_df['tokens'])\n",
    "raw_address = list(test_df['raw_address'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_pred1 = learn1.blurr_predict_tokens(raw_tokens)\n",
    "raw_pred2 = learn2.blurr_predict_tokens(raw_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob1 = [i[-1] for i in raw_pred1]\n",
    "prob2 = [i[-1] for i in raw_pred2]\n",
    "prob = [sum(x) for x in zip(prob1, prob2)]\n",
    "raw_preds = [dls.vocab[x.argmax(dim=1)] for x in prob]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_txts = [i[0] for i in raw_pred1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred1 = reconstruct(len(test_df), raw_pred1, raw_tokens, raw_address)\n",
    "pred2 = reconstruct(len(test_df), raw_pred2, raw_tokens, raw_address)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from string import punctuation\n",
    "\n",
    "def reconstruct(num, txt, pred, raw_tokens, raw_address):\n",
    "    def complete_word(x):\n",
    "        y = x.strip().strip(punctuation)\n",
    "        if y in wordlist:\n",
    "            x = x.replace(y, wordlist[y])\n",
    "        return x\n",
    "    \n",
    "    def normalize_bracket(x):\n",
    "        if '(' in x and ')' not in x:\n",
    "            x = x + ')'\n",
    "        elif ')' in x and '(' not in x:\n",
    "            x = '(' + x\n",
    "        return x\n",
    "    \n",
    "    ans = ['/'] * num\n",
    "    for idx in range(num):\n",
    "        res = pred[idx]\n",
    "        start_poi, end_poi = -1, -1\n",
    "        start_str, end_str = -1, -1\n",
    "        for i in range(len(txt[idx])):\n",
    "            if 'POI' in res[i]:\n",
    "                if start_poi == -1: start_poi = i\n",
    "                end_poi = i\n",
    "            if 'STR' in res[i]:\n",
    "                if start_str == -1: start_str = i\n",
    "                end_str = i\n",
    "        \n",
    "        if start_poi != -1:\n",
    "            txt1 = raw_address[idx]\n",
    "            for i in range(start_poi):\n",
    "                txt1 = txt1[len(raw_tokens[idx][i]):].strip()\n",
    "            for i in range(len(raw_tokens[idx]) - 1, end_poi, -1):\n",
    "                txt1 = txt1[:-len(raw_tokens[idx][i])].strip()\n",
    "            \n",
    "            txt1_check = ''.join(raw_tokens[idx][start_poi:end_poi + 1]).replace(' ', '')\n",
    "            assert txt1.replace(' ', '') == txt1_check\n",
    "            \n",
    "            last = len(txt1)\n",
    "            for i in range(end_poi, start_poi - 1, -1):\n",
    "                while last > 0 and txt1[last - 1] == ' ':\n",
    "                    last -= 1\n",
    "                assert last >= len(raw_tokens[idx][i])\n",
    "                last -= len(raw_tokens[idx][i])\n",
    "                if 'SHORT' in res[i]:\n",
    "                    txt1 = txt1[:last] + complete_word(raw_tokens[idx][i]) + txt1[last + len(raw_tokens[idx][i]):]\n",
    "        else:\n",
    "            txt1 = ''\n",
    "        \n",
    "        if start_str != -1:\n",
    "            txt2 = raw_address[idx]\n",
    "            for i in range(start_str):\n",
    "                txt2 = txt2[len(raw_tokens[idx][i]):].strip()\n",
    "            for i in range(len(raw_tokens[idx]) - 1, end_str, -1):\n",
    "                txt2 = txt2[:-len(raw_tokens[idx][i])].strip()\n",
    "            \n",
    "            txt2_check = ''.join(raw_tokens[idx][start_str:end_str + 1]).replace(' ', '')\n",
    "            assert txt2.replace(' ', '') == txt2_check\n",
    "            \n",
    "            last = len(txt2)\n",
    "            for i in range(end_str, start_str - 1, -1):\n",
    "                while last > 0 and txt2[last - 1] == ' ':\n",
    "                    last -= 1\n",
    "                assert last >= len(raw_tokens[idx][i])\n",
    "                last -= len(raw_tokens[idx][i])\n",
    "                if 'SHORT' in res[i]:\n",
    "                    txt2 = txt2[:last] + complete_word(raw_tokens[idx][i]) + txt2[last + len(raw_tokens[idx][i]):]\n",
    "        else:\n",
    "            txt2 = ''\n",
    "        \n",
    "        txt1 = txt1.strip(punctuation)\n",
    "        txt2 = txt2.strip(punctuation)\n",
    "        txt1 = normalize_bracket(txt1)\n",
    "        txt2 = normalize_bracket(txt2)\n",
    "        \n",
    "        ans[idx] = (txt1 + '/' + txt2)\n",
    "    \n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = reconstruct(len(test_df), raw_txts, raw_preds, raw_tokens, raw_address)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>raw_address</th>\n",
       "      <th>POI/street</th>\n",
       "      <th>tokens</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>90142</th>\n",
       "      <td>90142</td>\n",
       "      <td>lom 88 asrikaton</td>\n",
       "      <td>/</td>\n",
       "      <td>[lom, 88, asrikaton]</td>\n",
       "      <td>/lom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163531</th>\n",
       "      <td>163531</td>\n",
       "      <td>varia usaha ungaran, peri kem pudakpayung</td>\n",
       "      <td>/</td>\n",
       "      <td>[varia, usaha, ungaran,, peri, kem, pudakpayung]</td>\n",
       "      <td>varia usaha/peri kem</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233950</th>\n",
       "      <td>233950</td>\n",
       "      <td>hutan gar no 7 20371 percut sei tuan</td>\n",
       "      <td>/gar</td>\n",
       "      <td>[hutan, gar, no, 7, 20371, percut, sei, tuan]</td>\n",
       "      <td>/gar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126157</th>\n",
       "      <td>126157</td>\n",
       "      <td>wardah gor srik ton,</td>\n",
       "      <td>wardah gorden/srik ton</td>\n",
       "      <td>[wardah, gor, srik, ton,]</td>\n",
       "      <td>wardah goreng/srik ton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96808</th>\n",
       "      <td>96808</td>\n",
       "      <td>green puri 7 cengkareng</td>\n",
       "      <td>/green puri 7</td>\n",
       "      <td>[green, puri, 7, cengkareng]</td>\n",
       "      <td>/green puri 7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id                                raw_address  \\\n",
       "90142    90142                           lom 88 asrikaton   \n",
       "163531  163531  varia usaha ungaran, peri kem pudakpayung   \n",
       "233950  233950       hutan gar no 7 20371 percut sei tuan   \n",
       "126157  126157                       wardah gor srik ton,   \n",
       "96808    96808                    green puri 7 cengkareng   \n",
       "\n",
       "                    POI/street  \\\n",
       "90142                        /   \n",
       "163531                       /   \n",
       "233950                    /gar   \n",
       "126157  wardah gorden/srik ton   \n",
       "96808            /green puri 7   \n",
       "\n",
       "                                                  tokens  \\\n",
       "90142                               [lom, 88, asrikaton]   \n",
       "163531  [varia, usaha, ungaran,, peri, kem, pudakpayung]   \n",
       "233950     [hutan, gar, no, 7, 20371, percut, sei, tuan]   \n",
       "126157                         [wardah, gor, srik, ton,]   \n",
       "96808                       [green, puri, 7, cengkareng]   \n",
       "\n",
       "                          pred  \n",
       "90142                     /lom  \n",
       "163531    varia usaha/peri kem  \n",
       "233950                    /gar  \n",
       "126157  wardah goreng/srik ton  \n",
       "96808            /green puri 7  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df['pred'] = pred # pred1 pred2 \n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7422666666666666"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_acc(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7648888888888888"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_acc(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.76"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_acc(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_diff(test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>raw_address</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>s. par 53 sidanegara 4 cilacap tengah</td>\n",
       "      <td>[s., par, 53, sidanegara, 4, cilacap, tengah]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>angg per, baloi indah kel. lubuk baja</td>\n",
       "      <td>[angg, per,, baloi, indah, kel., lubuk, baja]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>asma laun, mand imog,</td>\n",
       "      <td>[asma, laun,, mand, imog,]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>ud agung rej, raya nga sri wedari karanganyar</td>\n",
       "      <td>[ud, agung, rej,, raya, nga, sri, wedari, karanganyar]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>cut mutia, 35 baiturrahman</td>\n",
       "      <td>[cut, mutia,, 35, baiturrahman]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                    raw_address  \\\n",
       "0   0          s. par 53 sidanegara 4 cilacap tengah   \n",
       "1   1          angg per, baloi indah kel. lubuk baja   \n",
       "2   2                          asma laun, mand imog,   \n",
       "3   3  ud agung rej, raya nga sri wedari karanganyar   \n",
       "4   4                     cut mutia, 35 baiturrahman   \n",
       "\n",
       "                                                   tokens  \n",
       "0           [s., par, 53, sidanegara, 4, cilacap, tengah]  \n",
       "1           [angg, per,, baloi, indah, kel., lubuk, baja]  \n",
       "2                              [asma, laun,, mand, imog,]  \n",
       "3  [ud, agung, rej,, raya, nga, sri, wedari, karanganyar]  \n",
       "4                         [cut, mutia,, 35, baiturrahman]  "
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real_test_df = pd.read_csv('test.csv')\n",
    "real_test_df['tokens'] = real_test_df['raw_address'].apply(clean).str.split()\n",
    "real_test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_tokens = list(real_test_df['tokens'])\n",
    "raw_address = list(real_test_df['raw_address'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_pred1 = learn1.blurr_predict_tokens(raw_tokens)\n",
    "raw_pred2 = learn2.blurr_predict_tokens(raw_tokens)\n",
    "\n",
    "prob1 = [i[-1] for i in raw_pred1]\n",
    "prob2 = [i[-1] for i in raw_pred2]\n",
    "prob = [sum(x) for x in zip(prob1, prob2)]\n",
    "raw_preds = [dls.vocab[x.argmax(dim=1)] for x in prob]\n",
    "\n",
    "raw_txts = [i[0] for i in raw_pred1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from string import punctuation\n",
    "\n",
    "def reconstruct(num, pred, raw_tokens, raw_address):\n",
    "    def complete_word(x):\n",
    "        y = x.strip().strip(punctuation)\n",
    "        if y != '' and y in wordlist:\n",
    "            x = x.replace(y, wordlist[y])\n",
    "        return x\n",
    "    \n",
    "    def normalize_bracket(x):\n",
    "        if '(' in x and ')' not in x:\n",
    "            x = x + ')'\n",
    "        elif ')' in x and '(' not in x:\n",
    "            x = '(' + x\n",
    "        return x\n",
    "    \n",
    "    ans = ['/'] * num\n",
    "    for idx in range(num):\n",
    "        res = pred[idx]\n",
    "        start_poi, end_poi = -1, -1\n",
    "        start_str, end_str = -1, -1\n",
    "        for i in range(len(res[0])):\n",
    "            if 'POI' in res[1][i]:\n",
    "                if start_poi == -1: start_poi = i\n",
    "                end_poi = i\n",
    "            if 'STR' in res[1][i]:\n",
    "                if start_str == -1: start_str = i\n",
    "                end_str = i\n",
    "        \n",
    "        if start_poi != -1:\n",
    "            txt1 = raw_address[idx]\n",
    "            for i in range(start_poi):\n",
    "                txt1 = txt1[len(raw_tokens[idx][i]):].strip()\n",
    "            for i in range(len(raw_tokens[idx]) - 1, end_poi, -1):\n",
    "                txt1 = txt1[:-len(raw_tokens[idx][i])].strip()\n",
    "            \n",
    "            txt1_check = ''.join(raw_tokens[idx][start_poi:end_poi + 1]).replace(' ', '')\n",
    "            assert txt1.replace(' ', '') == txt1_check\n",
    "            \n",
    "            last = len(txt1)\n",
    "            for i in range(end_poi, start_poi - 1, -1):\n",
    "                while last > 0 and txt1[last - 1] == ' ':\n",
    "                    last -= 1\n",
    "                assert last >= len(raw_tokens[idx][i])\n",
    "                last -= len(raw_tokens[idx][i])\n",
    "                if 'SHORT' in res[1][i]:\n",
    "                    txt1 = txt1[:last] + complete_word(raw_tokens[idx][i]) + txt1[last + len(raw_tokens[idx][i]):]\n",
    "        else:\n",
    "            txt1 = ''\n",
    "        \n",
    "        if start_str != -1:\n",
    "            txt2 = raw_address[idx]\n",
    "            for i in range(start_str):\n",
    "                txt2 = txt2[len(raw_tokens[idx][i]):].strip()\n",
    "            for i in range(len(raw_tokens[idx]) - 1, end_str, -1):\n",
    "                txt2 = txt2[:-len(raw_tokens[idx][i])].strip()\n",
    "            \n",
    "            txt2_check = ''.join(raw_tokens[idx][start_str:end_str + 1]).replace(' ', '')\n",
    "            assert txt2.replace(' ', '') == txt2_check\n",
    "            \n",
    "            last = len(txt2)\n",
    "            for i in range(end_str, start_str - 1, -1):\n",
    "                while last > 0 and txt2[last - 1] == ' ':\n",
    "                    last -= 1\n",
    "                assert last >= len(raw_tokens[idx][i])\n",
    "                last -= len(raw_tokens[idx][i])\n",
    "                if 'SHORT' in res[1][i]:\n",
    "                    txt2 = txt2[:last] + complete_word(raw_tokens[idx][i]) + txt2[last + len(raw_tokens[idx][i]):]\n",
    "        else:\n",
    "            txt2 = ''\n",
    "        \n",
    "        txt1 = txt1.strip(punctuation)\n",
    "        txt2 = txt2.strip(punctuation)\n",
    "        txt1 = normalize_bracket(txt1)\n",
    "        txt2 = normalize_bracket(txt2)\n",
    "        \n",
    "        ans[idx] = (txt1 + '/' + txt2)\n",
    "    \n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred1 = reconstruct(len(real_test_df), raw_pred1, raw_tokens, raw_address)\n",
    "pred2 = reconstruct(len(real_test_df), raw_pred2, raw_tokens, raw_address)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "from string import punctuation\n",
    "\n",
    "def reconstruct(num, txt, pred, raw_tokens, raw_address):\n",
    "    def complete_word(x):\n",
    "        y = x.strip().strip(punctuation)\n",
    "        if y in wordlist:\n",
    "            x = x.replace(y, wordlist[y])\n",
    "        return x\n",
    "    \n",
    "    def normalize_bracket(x):\n",
    "        if '(' in x and ')' not in x:\n",
    "            x = x + ')'\n",
    "        elif ')' in x and '(' not in x:\n",
    "            x = '(' + x\n",
    "        return x\n",
    "    \n",
    "    ans = ['/'] * num\n",
    "    for idx in range(num):\n",
    "        res = pred[idx]\n",
    "        start_poi, end_poi = -1, -1\n",
    "        start_str, end_str = -1, -1\n",
    "        for i in range(len(txt[idx])):\n",
    "            if 'POI' in res[i]:\n",
    "                if start_poi == -1: start_poi = i\n",
    "                end_poi = i\n",
    "            if 'STR' in res[i]:\n",
    "                if start_str == -1: start_str = i\n",
    "                end_str = i\n",
    "        \n",
    "        if start_poi != -1:\n",
    "            txt1 = raw_address[idx]\n",
    "            for i in range(start_poi):\n",
    "                txt1 = txt1[len(raw_tokens[idx][i]):].strip()\n",
    "            for i in range(len(raw_tokens[idx]) - 1, end_poi, -1):\n",
    "                txt1 = txt1[:-len(raw_tokens[idx][i])].strip()\n",
    "            \n",
    "            txt1_check = ''.join(raw_tokens[idx][start_poi:end_poi + 1]).replace(' ', '')\n",
    "            assert txt1.replace(' ', '') == txt1_check\n",
    "            \n",
    "            last = len(txt1)\n",
    "            for i in range(end_poi, start_poi - 1, -1):\n",
    "                while last > 0 and txt1[last - 1] == ' ':\n",
    "                    last -= 1\n",
    "                assert last >= len(raw_tokens[idx][i])\n",
    "                last -= len(raw_tokens[idx][i])\n",
    "                if 'SHORT' in res[i]:\n",
    "                    txt1 = txt1[:last] + complete_word(raw_tokens[idx][i]) + txt1[last + len(raw_tokens[idx][i]):]\n",
    "        else:\n",
    "            txt1 = ''\n",
    "        \n",
    "        if start_str != -1:\n",
    "            txt2 = raw_address[idx]\n",
    "            for i in range(start_str):\n",
    "                txt2 = txt2[len(raw_tokens[idx][i]):].strip()\n",
    "            for i in range(len(raw_tokens[idx]) - 1, end_str, -1):\n",
    "                txt2 = txt2[:-len(raw_tokens[idx][i])].strip()\n",
    "            \n",
    "            txt2_check = ''.join(raw_tokens[idx][start_str:end_str + 1]).replace(' ', '')\n",
    "            assert txt2.replace(' ', '') == txt2_check\n",
    "            \n",
    "            last = len(txt2)\n",
    "            for i in range(end_str, start_str - 1, -1):\n",
    "                while last > 0 and txt2[last - 1] == ' ':\n",
    "                    last -= 1\n",
    "                assert last >= len(raw_tokens[idx][i])\n",
    "                last -= len(raw_tokens[idx][i])\n",
    "                if 'SHORT' in res[i]:\n",
    "                    txt2 = txt2[:last] + complete_word(raw_tokens[idx][i]) + txt2[last + len(raw_tokens[idx][i]):]\n",
    "        else:\n",
    "            txt2 = ''\n",
    "        \n",
    "        txt1 = txt1.strip(punctuation)\n",
    "        txt2 = txt2.strip(punctuation)\n",
    "        txt1 = normalize_bracket(txt1)\n",
    "        txt2 = normalize_bracket(txt2)\n",
    "        \n",
    "        ans[idx] = (txt1 + '/' + txt2)\n",
    "    \n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = reconstruct(len(real_test_df), raw_txts, raw_preds, raw_tokens, raw_address)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_test_df['POI/street'] = pred2 # pred1 pred2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>POI/street</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>/s. par</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>/angg per</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>asma laundry/mand imog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>ud agung rejeki/raya nga</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>/cut mutia</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                POI/street\n",
       "0   0                   /s. par\n",
       "1   1                 /angg per\n",
       "2   2    asma laundry/mand imog\n",
       "3   3  ud agung rejeki/raya nga\n",
       "4   4                /cut mutia"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# real_test_df.drop(columns=['raw_address', 'tokens'], inplace=True)\n",
    "real_test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_test_df.to_csv('bert-indo-final.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
